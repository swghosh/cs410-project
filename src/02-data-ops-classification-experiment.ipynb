{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5670a62",
   "metadata": {},
   "source": [
    "**Alert: \\[Experimental Approach\\]** This approach was not used in the final project UI which was deployed. If you're looking for the final approach, consider seeing [other notebook: 03-data-ops-classification-final.ipynb](./03-data-ops-classification-final.ipynb) instead.\n",
    "\n",
    "<hr>\n",
    "\n",
    "This approach did not yield good results on the classification performance of the actual downstream task. It was identified that the root cause for such mis-classification was a result of manually created labels which were not robust enough to classify the data properly.\n",
    "\n",
    "In this notebook, we use the pre-processed dataset prepared in the [previous notebook: 01-data-ops-preprocessing.ipynb](./01-data-ops-preprocessing.ipynb) and try to use it to do the following:\n",
    "\n",
    "1. Manually label each shell script / batch file contents on the basis of gathered keywords\n",
    "2. Score them using a Bag of Words based unigram token giving a reward for each keyword matched across corresponding labels\n",
    "3. Aggregate the counts of the relevant keywords and select the label of the document based upon highest rewards for each category.\n",
    "4. Split the dataset into 70:30 ratio for training and testing\n",
    "5. Train the classifier using Bag of Words tokenization + TFIDF preprocessing in the pipeline followed by comparing results of SVM classifier and Naive Bayes classifier.\n",
    "\n",
    "**Challenges (with RCA)**: As a result of the manually creation of labels, the classification data wasn't robust in terms of labelling causing classification failures for almost all queries. Also, the 'unknown' class was dominant in the classification problem and as a result of curse of imbalance faced by classifiers, it almost always will classify unknown which wasn't relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343371f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import metapy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cf5511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>size</th>\n",
       "      <th>content</th>\n",
       "      <th>sample_repo_name</th>\n",
       "      <th>sample_path</th>\n",
       "      <th>original_content</th>\n",
       "      <th>source_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9cf4a93718cce2c5bcfd5caf5ecbd8f0c1ae4a6</td>\n",
       "      <td>221</td>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\nenv | sed 's/^/export /...</td>\n",
       "      <td>SpisTresci/SpisTresci</td>\n",
       "      <td>compose/django/cron.sh</td>\n",
       "      <td></td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9aaa28acde02cba18658aa4f2eb335fb4cf20b7</td>\n",
       "      <td>265</td>\n",
       "      <td>#!/bin/sh -f\\nxv_path=\"/home/huchao/vivado/Viv...</td>\n",
       "      <td>chaohu/Daily-Learning</td>\n",
       "      <td>Verilog/lab2/lab2_1/lab1_2_2/lab1_2_2.sim/sim_...</td>\n",
       "      <td></td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2f1c35188379847bdb4d907196bb7f2dd7a515f7</td>\n",
       "      <td>376</td>\n",
       "      <td>#!/bin/bash\\n#--------------------------------...</td>\n",
       "      <td>BeeeOn/android</td>\n",
       "      <td>tests/monkey/kill-test.sh</td>\n",
       "      <td></td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04fe6cd6b11a81f12a91bd6effd318d2483a17d9</td>\n",
       "      <td>89</td>\n",
       "      <td>#!/bin/bash\\nrabbitmq-plugins enable rabbitmq_...</td>\n",
       "      <td>oscm/shell</td>\n",
       "      <td>mq/rabbitmq/enable.rabbitmq_management.sh</td>\n",
       "      <td></td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b46ba78936c1ec41fbf4aed15a876d858432db88</td>\n",
       "      <td>1905</td>\n",
       "      <td>{% if cluster.type == 'ec2' -%}\\n#$ -q all.q@@...</td>\n",
       "      <td>Kitware/HPCCloud</td>\n",
       "      <td>server/taskflows/hpccloud/taskflow/pvw.sh</td>\n",
       "      <td></td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  size  \\\n",
       "0  c9cf4a93718cce2c5bcfd5caf5ecbd8f0c1ae4a6   221   \n",
       "1  c9aaa28acde02cba18658aa4f2eb335fb4cf20b7   265   \n",
       "2  2f1c35188379847bdb4d907196bb7f2dd7a515f7   376   \n",
       "3  04fe6cd6b11a81f12a91bd6effd318d2483a17d9    89   \n",
       "4  b46ba78936c1ec41fbf4aed15a876d858432db88  1905   \n",
       "\n",
       "                                             content       sample_repo_name  \\\n",
       "0  #!/bin/bash\\nset -e\\n\\nenv | sed 's/^/export /...  SpisTresci/SpisTresci   \n",
       "1  #!/bin/sh -f\\nxv_path=\"/home/huchao/vivado/Viv...  chaohu/Daily-Learning   \n",
       "2  #!/bin/bash\\n#--------------------------------...         BeeeOn/android   \n",
       "3  #!/bin/bash\\nrabbitmq-plugins enable rabbitmq_...             oscm/shell   \n",
       "4  {% if cluster.type == 'ec2' -%}\\n#$ -q all.q@@...       Kitware/HPCCloud   \n",
       "\n",
       "                                         sample_path original_content  \\\n",
       "0                             compose/django/cron.sh                    \n",
       "1  Verilog/lab2/lab2_1/lab1_2_2/lab1_2_2.sim/sim_...                    \n",
       "2                          tests/monkey/kill-test.sh                    \n",
       "3          mq/rabbitmq/enable.rabbitmq_management.sh                    \n",
       "4          server/taskflows/hpccloud/taskflow/pvw.sh                    \n",
       "\n",
       "  source_category  \n",
       "0             .sh  \n",
       "1             .sh  \n",
       "2             .sh  \n",
       "3             .sh  \n",
       "4             .sh  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('./web/data/dataset.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7e49f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>source_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#!/bin/bash\\nset -e\\n\\nenv | sed 's/^/export /...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#!/bin/sh -f\\nxv_path=\"/home/huchao/vivado/Viv...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#!/bin/bash\\n#--------------------------------...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#!/bin/bash\\nrabbitmq-plugins enable rabbitmq_...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{% if cluster.type == 'ec2' -%}\\n#$ -q all.q@@...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content source_category\n",
       "0  #!/bin/bash\\nset -e\\n\\nenv | sed 's/^/export /...             .sh\n",
       "1  #!/bin/sh -f\\nxv_path=\"/home/huchao/vivado/Viv...             .sh\n",
       "2  #!/bin/bash\\n#--------------------------------...             .sh\n",
       "3  #!/bin/bash\\nrabbitmq-plugins enable rabbitmq_...             .sh\n",
       "4  {% if cluster.type == 'ec2' -%}\\n#$ -q all.q@@...             .sh"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_req = df.copy().drop(columns=['id', 'sample_repo_name', 'sample_path', 'original_content', 'size'])\n",
    "df_req.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958a1172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>source_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13699</th>\n",
       "      <td>#!/bin/bash\\n# -------------------------------...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>#!/bin/sh\\n\\n### BEGIN INIT INFO\\n# Provides: ...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>curl -i -X POST -H \"Content-Type: application/...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>#!/bin/sh\\ncd `dirname \"$0\"`\\nvalgrind --error...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>#!/bin/bash\\n#\\n# This script assumes a linux ...</td>\n",
       "      <td>.sh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content source_category\n",
       "13699  #!/bin/bash\\n# -------------------------------...             .sh\n",
       "9141   #!/bin/sh\\n\\n### BEGIN INIT INFO\\n# Provides: ...             .sh\n",
       "3863   curl -i -X POST -H \"Content-Type: application/...             .sh\n",
       "5406   #!/bin/sh\\ncd `dirname \"$0\"`\\nvalgrind --error...             .sh\n",
       "5728   #!/bin/bash\\n#\\n# This script assumes a linux ...             .sh"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_req = shuffle(df_req)\n",
    "df_req.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb77c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'rhel/fedora': [\n",
    "        'systemctl',\n",
    "        'useradd', 'passwd', 'userdel',\n",
    "        'os', 'fedora', 'rhel', 'uname', 'cat',\n",
    "        'podman', 'oc', 'yum', 'dnf',\n",
    "        'microdnf', 'subscription', 'manager',\n",
    "        'ubi', 'ip', 'journalctl', 'selinux'\n",
    "    ],\n",
    "    'ubuntu/debian': [\n",
    "        'apt', 'get', 'dpkg',\n",
    "        'debian', 'ubuntu', 'systemctl',\n",
    "        'useradd', 'passwd', 'userdel',\n",
    "        'lsb', 'uname', 'cat', 'lts', 'ifconfig',\n",
    "        'ip'\n",
    "    ],\n",
    "    'windows': [\n",
    "        'systeminfo', 'ver', 'choco',\n",
    "        'sc', 'net', 'ipconfig', 'reg',\n",
    "        'cmd', 'powershell', 'msiexec', 'chdir',\n",
    "        'call', 'rmdir', 'move', 'cls', 'assoc', 'tasklist'\n",
    "    ],\n",
    "    'others/unknown': [\n",
    "        'apk', 'pacman', 'alpine', 'arch',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d82fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_set = set()\n",
    "\n",
    "def preprocess(content):\n",
    "    tok = metapy.analyzers.ICUTokenizer(suppress_tags=True)\n",
    "    ngram = metapy.analyzers.NGramWordAnalyzer(1, tok)\n",
    "    \n",
    "    try:\n",
    "        doc = metapy.index.Document()\n",
    "        doc.content(content)\n",
    "        unigrams = ngram.analyze(doc)\n",
    "        \n",
    "        tok.set_content(doc.content())\n",
    "    except:\n",
    "        return {}\n",
    "    \n",
    "    tokens_counts = {}\n",
    "    for token, count in unigrams.items():\n",
    "        tokens_counts[token] = count\n",
    "        token_set.add(token)\n",
    "    \n",
    "    return tokens_counts\n",
    "\n",
    "# manual labelling use gather keywords rewards\n",
    "def label(contents, source_category):\n",
    "    tc = preprocess(contents)\n",
    "    ctr = {}\n",
    "    for key in keywords:\n",
    "        ctr[key] = 0\n",
    "    \n",
    "    for cat in keywords:\n",
    "        for kw in keywords[cat]:\n",
    "            if kw in tc:\n",
    "                ctr[cat] += 1\n",
    "    \n",
    "    cat_names = np.array([key for key in ctr])\n",
    "    cats = np.array([ctr[key] for key in cat_names])\n",
    "    i0 = np.argmax(cats)\n",
    "    \n",
    "    cats1 = cats.copy()\n",
    "    cats1[i0] = -1\n",
    "    i1 = np.argmax(cats1)\n",
    "    if ctr[cat_names[i0]] == ctr[cat_names[i1]]:\n",
    "        if source_category == '.bat':\n",
    "            return 'windows'\n",
    "        else:\n",
    "            return 'others/unknown'\n",
    "    \n",
    "    cat = cat_names[i0]\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bef643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens in corpus: 258421\n",
      "dataset distribution: {'rhel/fedora': 478, 'ubuntu/debian': 2480, 'windows': 2674, 'others/unknown': 13611}\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for _, row in df.iterrows():\n",
    "    labels.append(label(row.content, row.source_category))\n",
    "\n",
    "print('total tokens in corpus:', len(token_set))\n",
    "\n",
    "ctr = {k: 0 for k in keywords}\n",
    "for label in labels:\n",
    "    ctr[label] += 1\n",
    "\n",
    "print('dataset distribution:', ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad7f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {'rhel/fedora': 0, 'ubuntu/debian': 1, 'windows': 2, 'others/unknown': 3}\n",
    "rev_cats = {0: 'rhel/fedora', 1: 'ubuntu/debian', 2: 'windows', 3: 'others/unknown'}\n",
    "label_cats = [cats[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee8655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_req.content)\n",
    "y = np.array(label_cats)\n",
    "\n",
    "# ignore empty contents\n",
    "for i in range(len(X)):\n",
    "    if X[i] is None:\n",
    "        X[i] = ''\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdd457",
   "metadata": {},
   "source": [
    "SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e6943f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SVC())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d43853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       145\n",
      "           1       0.33      0.00      0.00       737\n",
      "           2       0.00      0.00      0.00       811\n",
      "           3       0.71      1.00      0.83      4080\n",
      "\n",
      "    accuracy                           0.71      5773\n",
      "   macro avg       0.26      0.25      0.21      5773\n",
      "weighted avg       0.54      0.71      0.59      5773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swghosh/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/swghosh/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/swghosh/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "print('SVM Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd32d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample user queries\n",
    "\n",
    "queries = [\n",
    "    'sudo apt-get install git', # ground truth: rhel/fedora\n",
    "    'cls rem rmdir', # windows\n",
    "    'sudo dnf install -y code', # ubuntu/debian\n",
    "    'apk add golang' # unknown/others\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19cf9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sudo apt-get install git': 'others/unknown'}, {'cls rem rmdir': 'others/unknown'}, {'sudo dnf install -y code': 'others/unknown'}, {'apk add golang': 'others/unknown'}]\n"
     ]
    }
   ],
   "source": [
    "clfe = svm_clf.predict(np.array(queries))\n",
    "print([{q: rev_cats[i]} for q, i in zip(queries, clfe)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805e356",
   "metadata": {},
   "source": [
    "Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6056f922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fdecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       145\n",
      "           1       0.00      0.00      0.00       737\n",
      "           2       0.00      0.00      0.00       811\n",
      "           3       0.71      1.00      0.83      4080\n",
      "\n",
      "    accuracy                           0.71      5773\n",
      "   macro avg       0.18      0.25      0.21      5773\n",
      "weighted avg       0.50      0.71      0.59      5773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swghosh/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/swghosh/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/swghosh/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "print('Naive Bayes Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7cf8434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sudo apt-get install git': 'others/unknown'}, {'cls rem rmdir': 'others/unknown'}, {'sudo dnf install -y code': 'others/unknown'}, {'apk add golang': 'others/unknown'}]\n"
     ]
    }
   ],
   "source": [
    "# sample user query\n",
    "clfe = nb_clf.predict(np.array(queries))\n",
    "print([{q: rev_cats[i]} for q, i in zip(queries, clfe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f1cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
